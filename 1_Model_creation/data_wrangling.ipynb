{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0efb049-63b0-4a58-9baa-72895047864b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers, backend\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import os, math, random, imagesize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c1b06f-8cb4-49ac-b819-d5854c80a9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBALS\n",
    "DATA_DIR = \"data/\"\n",
    "\n",
    "IMAGE_SIZE = 256 \n",
    "IMAGE_SHAPE = (IMAGE_SIZE, IMAGE_SIZE)\n",
    "CHANNELS = 3\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30\n",
    "IMG_TENSOR_SHAPE = (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\n",
    "\n",
    "BATCHED_DATASET = tf.keras.preprocessing.image_dataset_from_directory(DATA_DIR, shuffle=False,  image_size=IMAGE_SHAPE, batch_size=BATCH_SIZE)\n",
    "NUM_BATCHES = len(BATCHED_DATASET)\n",
    "\n",
    "FILE_PATHS = BATCHED_DATASET.file_paths\n",
    "CLASS_NAMES = BATCHED_DATASET.class_names\n",
    "NUM_CLASSES = len(CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78312f14-8dec-46cc-a8d1-39cc19dd5523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unbatch the data to include the filepath\n",
    "UNBATCHED_DATASET = BATCHED_DATASET.unbatch()\n",
    "images = list(UNBATCHED_DATASET.map(lambda x, y: x))\n",
    "labels = list(UNBATCHED_DATASET.map(lambda x, y: y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231b86b4-0275-48b3-a8d7-a682933b2021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_path_batch(file_paths, num_batches, batch_size, shape, dtype=tf.string):\n",
    "    strings_need_to_fill_last_batch = NUM_BATCHES*BATCH_SIZE - len(FILE_PATHS)    \n",
    "    extended_file_paths = file_paths[:] + [\"N/a\" for i in range(strings_need_to_fill_last_batch)]\n",
    "    file_names_tensor = tf.reshape(tf.constant(extended_file_paths, dtype=dtype), shape)\n",
    "    return file_names_tensor\n",
    "\n",
    "def add_file_paths_to_dataset(ds=None):\n",
    "    \"\"\"https://stackoverflow.com/questions/70260531/how-to-attach-or-get-filenames-from-mapdataset-from-image-dataset-from-directory\"\"\"\n",
    "    if ds == None:\n",
    "        ds = tf.keras.utils.image_dataset_from_directory(DATA_DIR, shuffle=False, batch_size=BATCH_SIZE)\n",
    "    normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "    \n",
    "    def change_inputs(images, labels, paths):\n",
    "        x = normalization_layer(images)\n",
    "        return x, labels, tf.stack([tuple(paths)])\n",
    "        \n",
    "    def map_inputs(images, labels, paths):\n",
    "        images = tf.cast(images, dtype=tf.uint8)\n",
    "        paths = tf.constant(((paths)), tf.string)\n",
    "        return images, images, paths\n",
    "    \n",
    "    return ds.map(lambda images, labels: map_inputs(images, labels, paths=ds.file_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55c8007-1515-432a-ad98-9946f21c3dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAMES_TENSOR = file_path_batch(FILE_PATHS, NUM_BATCHES, BATCH_SIZE, [NUM_BATCHES, BATCH_SIZE])\n",
    "batched_with_file_paths = add_file_paths_to_dataset()\n",
    "FILE_NAMES_TENSOR, batched_with_file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109b8e14-3de9-4250-975d-aefc3fe0545e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(data_dir: str, shape: tuple=(256,256), keep_aspect_ratio: bool=True):\n",
    "    Path(data_dir + \"\\\\resize\\\\keep_aspect\").mkdir(parents=True, exist_ok=True)\n",
    "    Path(data_dir + \"\\\\resize\\\\no_aspect\").mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for img_path in Path(data_dir).glob(\"*.*\"):\n",
    "        img_path = img_path.name\n",
    "        if keep_aspect_ratio:\n",
    "            with Image.open(data_dir + \"\\\\\" + img_path) as img: # accepts: .png & .jpg\n",
    "                im = img.resize(shape, Image.ANTIALIAS)\n",
    "                im.save(data_dir + \"\\\\resize\\\\no_aspect\\\\\" + img_path, \"JPEG\")\n",
    "        else:\n",
    "            with Image.open(data_dir + \"\\\\\" + img_path) as im:\n",
    "                im.thumbnail(shape, Image.ANTIALIAS)\n",
    "                im.save(data_dir + \"\\\\resize\\\\keep_aspect\\\\\" + img_path, \"JPEG\")\n",
    "\n",
    "\n",
    "def move_ill_shaped_images(data_dir: str, shape: tuple=(256,256)):\n",
    "    \"\"\" Moves ill shaped images to a folder in the data folder \"\"\"\n",
    "    for img_path in _find_images_with_incorrect_dims(data_dir, shape):\n",
    "        label = img_path.split(\"\\\\\")[0]\n",
    "        p = Path(f\"{data_dir}\\\\_problem_children\\\\{label}\")\n",
    "        if not p.exists():\n",
    "            p.mkdir(parents=True, exist_ok=True)\n",
    "        Path(f\"{data_dir}\\\\{img_path}\").replace(f\"{data_dir}\\\\_problem_children\\\\{img_path}\")\n",
    "\n",
    "\n",
    "def delete_ill_shaped_images(data_dir: str, shape: tuple):\n",
    "    for img_path in _find_images_with_incorrect_dims(data_dir, shape):\n",
    "        Path(f\"{data_dir}\\\\{img_path}\").unlink(missing_ok=True)\n",
    "\n",
    "\n",
    "def _find_images_with_incorrect_dims(relative_data_path: str, desired_shape: tuple, ignore_problem_children: bool=True):\n",
    "    \"\"\" returns a list relative paths to each image with an incorrect shape \"\"\"\n",
    "    size_mismatch = []\n",
    "    for dirs_winp in Path(relative_data_path).glob(\"*\"):\n",
    "        if ignore_problem_children and dirs_winp.name == \"_problem_children\":\n",
    "                continue\n",
    "        for image_winp in Path(f\"{dirs_winp}\\\\\").glob(\"*\"):\n",
    "            if imagesize.get(str(image_winp)) != desired_shape:\n",
    "                size_mismatch.append(f\"{dirs_winp.name}\\\\{image_winp.name}\")\n",
    "    return size_mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5604b9-5045-4473-9a4f-5ea9d5d5d317",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_tf_dataset_train_val_test(ds, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=10000):\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(shuffle_size)\n",
    "    train_set = ds.take(round(NUM_BATCHES * train_split))\n",
    "    val_set = ds.skip(len(train_set)).take(round(len(ds) * val_split))\n",
    "    test_set = ds.skip(len(train_set)+len(val_set)).take(-1)\n",
    "    return train_set, val_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12321601-6686-40cb-9468-8f051659a8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set, test_set = split_tf_dataset_train_val_test(BATCHED_DATASET, shuffle=True)\n",
    "print(len(train_set), len(val_set), len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65466cad-8bed-4de7-ba99-32b38aea1826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(model, img):\n",
    "    img_array = tf.expand_dims(tf.keras.preprocessing.image.img_to_array(img), 0)\n",
    "    preds = model.predict(img_array)[0]\n",
    "    pred_label = CLASS_NAMES[np.argmax(preds)]\n",
    "    confidence = round(100 * (np.max(preds)), 2)\n",
    "    return pred_label, confidence\n",
    "\n",
    "\n",
    "def display_single_prediction_from_set(from_set):\n",
    "    for images_batch, labels_batch in from_set.take(1):\n",
    "        index = random.randint(0, len(images_batch)-1)\n",
    "        image = images_batch[index].numpy().astype(\"uint8\")\n",
    "        actu_label = CLASS_NAMES[labels_batch[index].numpy()]\n",
    "        pred_label, conf = predict_image(CNN, image)\n",
    "        print(f\"Predicted Label: {pred_label}\")\n",
    "        print(f\"Actual Label:    {actu_label}\")    \n",
    "        print(f\"Confidence:      {conf}\") \n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(image)\n",
    "\n",
    "\n",
    "def display_multiple_predictions(from_set, num_rows, num_cols):\n",
    "    num_images = num_rows*num_cols\n",
    "    plt.figure(figsize=(16, num_images*2))\n",
    "    for images, labels in from_set.take(1):\n",
    "        for i in range(num_images):\n",
    "            pred_label, conf = predict_image(CNN, images[i].numpy())\n",
    "            actual_label = CLASS_NAMES[labels[i]]\n",
    "            plt.subplot(num_rows, num_cols, i+1)            \n",
    "            plt.title(f\"Actual: {actual_label}, \\n Predicted: {pred_label}, \\n Confidence: {conf}\")\n",
    "            plt.axis(\"off\")\n",
    "            plt.imshow(images[i].numpy().astype(\"uint8\"))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383e564b-dc6a-437b-84e8-93e60096689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of images per class\n",
    "dict_class_size = dict(zip([i for i in os.listdir(DATA_DIR)], [len(os.listdir(DATA_DIR+\"//\"+label)) for label in CLASS_NAMES]))\n",
    "dict_class_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28633799-e3e3-4e81-86e0-f7a62dac25ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Undersampling Algorithms for Imbalanced Classification\n",
    "https://machinelearningmastery.com/undersampling-algorithms-for-imbalanced-classification/\n",
    "- Random OVERSAMPLING duplicates examples from the minority class in the training dataset \n",
    "  and can result in overfitting for some models.\n",
    "- Random UNDERSAMPLING deletes examples from the majority class and can result in losing \n",
    "  information invaluable to a model.\n",
    "https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/\n",
    "https://machinelearningmastery.com/tour-of-evaluation-metrics-for-imbalanced-classification/\n",
    "https://www.analyticsvidhya.com/blog/2020/07/10-techniques-to-deal-with-class-imbalance-in-machine-learning/\n",
    "\"\"\"\n",
    "import imblearn as imb\n",
    "from imblearn.under_sampling import NearMiss, CondensedNearestNeighbour, TomekLinks, EditedNearestNeighbours, OneSidedSelection, NeighbourhoodCleaningRule\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from numpy import where\n",
    "\n",
    "NearMiss1 = NearMiss(version=1, n_neighbors=3)\n",
    "NearMiss2 = NearMiss(version=2, n_neighbors=3)\n",
    "NearMiss3 = NearMiss(version=3, n_neighbors=3)\n",
    "tomeks_links = TomekLinks()\n",
    "  # In practice, Tomek Links procedure is often combined with other methods, \n",
    "  # such as the Condensed Nearest Neighbor Rule. (OSS)\n",
    "OSS = OneSidedSelection(n_neighbors=1, n_seeds_S=200)\n",
    "  # Tomek Links are identified and removed in the majority class. \n",
    "  # CNN then removes redundant majority class examples far from the decision boundary.\n",
    "CNN = CondensedNearestNeighbour(n_neighbors=1)\n",
    "  # 1:2 minority to majority examples  seeks to balance the class distribution, the algorithm will continue to add misclassified examples to the store (transformed dataset). This is a desirable property.\n",
    "ENN = EditedNearestNeighbours(n_neighbors=3) \n",
    "  # Also best when combined with another undersampling procedure\n",
    "NCR = NeighbourhoodCleaningRule(n_neighbors=3, threshold_cleaning=0.5)\n",
    "  # (CNN) Rule to remove redundant examples and the Edited Nearest Neighbors (ENN) Rule to remove noisy or ambiguous examples.\n",
    "dataset_params = dict(n_samples=10000, n_features=2, n_redundant=0, n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=1)\n",
    "\n",
    "for undersample in [NCR]:\n",
    "    X, y = make_classification(**dataset_params)\n",
    "    initial_dist = Counter(y)\n",
    "    X, y = undersample.fit_resample(X, y)\n",
    "    resulting_dist = Counter(y)\n",
    "    for label, _ in counter.items():\n",
    "        row_ix = where(y == label)[0]\n",
    "        plt.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))\n",
    "    print(initial_dist, resulting_dist)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33269268-4639-4bcb-8485-e4080f9e45d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
