{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "536c4d4e-d308-462a-92fc-54c530f63f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers, backend\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import os, math, random, imagesize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb15219-e747-4aeb-a4f4-5a82c1b4690a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBALS\n",
    "DATA_DIR = \"data/\"\n",
    "IMAGE_SIZE = 256 \n",
    "IMAGE_SHAPE = (IMAGE_SIZE, IMAGE_SIZE)\n",
    "CHANNELS = 3\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30\n",
    "IMG_TENSOR_SHAPE = (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\n",
    "\n",
    "BATCHED_DATASET = tf.keras.preprocessing.image_dataset_from_directory(DATA_DIR, shuffle=True,  image_size=IMAGE_SHAPE, batch_size=BATCH_SIZE)\n",
    "NUM_BATCHES = len(BATCHED_DATASET)\n",
    "\n",
    "FILE_PATHS = BATCHED_DATASET.file_paths\n",
    "CLASS_NAMES = BATCHED_DATASET.class_names\n",
    "NUM_CLASSES = len(CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406b9891-4a82-4f54-97bb-a40c0cbdd54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_partitioned_tf_dataset(ds, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=10000):\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(shuffle_size, seed=43)\n",
    "    train_set = ds.take(round(NUM_BATCHES * train_split))\n",
    "    val_set = ds.skip(len(train_set)).take(round(len(ds) * val_split))\n",
    "    test_set = ds.skip(len(train_set)+len(val_set)).take(-1)\n",
    "    return train_set, val_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce0dd76-c109-45e4-a13b-410ed2be5e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set, test_set = get_partitioned_tf_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e91d82-da0c-426c-80d3-35ef57ffd2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_set.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_set = val_set.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_set = test_set.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefdd3d1-de32-45f0-a0c6-91efb7b27fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_and_scale_layer = tf.keras.Sequential([\n",
    "    layers.experimental.preprocessing.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    layers.experimental.preprocessing.Rescaling(1.0/255)\n",
    "])\n",
    "\n",
    "data_augmentation_layer = tf.keras.Sequential([\n",
    "    layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b90328c1-00c3-402b-b660-58103a63c797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn(name=\"CNN\", image_shape=None):\n",
    "    backend.clear_session()\n",
    "    model = models.Sequential([\n",
    "        resize_and_scale_layer,\n",
    "        data_augmentation_layer,\n",
    "    \n",
    "        layers.Conv2D(32, (3,3), activation=\"relu\", input_shape=image_shape),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "    \n",
    "        layers.Conv2D(64, (3,3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "    \n",
    "        layers.Conv2D(64, (3,3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "    \n",
    "        layers.Conv2D(64, (3,3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "    \n",
    "        layers.Conv2D(64, (3,3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "    \n",
    "        layers.Conv2D(64, (3,3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "    \n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(NUM_CLASSES, activation=\"softmax\")\n",
    "    ], name=\"CNN\")\n",
    "\n",
    "    model.build(input_shape=image_shape)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de3a881-bc83-4d40-9a94-49f0e555bb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN = build_cnn(image_shape=IMG_TENSOR_SHAPE)\n",
    "CNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d09db99-2faa-469d-a636-600e372fb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_test(model, train, val, test, batch_size=BATCH_SIZE, epochs=EPOCHS):\n",
    "    history = model.fit(train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=val)\n",
    "    test_score = model.evaluate(test)\n",
    "    return history, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab783a7-5e25-4aeb-b6af-2d67e33918b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN = build_cnn(image_shape=IMG_TENSOR_SHAPE)\n",
    "nadam = CNN.compile(\n",
    "    optimizer=\"Nadam\", \n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    ")\n",
    "nadam_history, nadam_test_score = fit_and_test(CNN, train_set, val_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b45c2e1-cdb6-43d9-ad40-c7a24c89f770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots the train and validation acc & loss for the model history given\n",
    "def plot_train_vs_val(model_history, epochs=EPOCHS):\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    plt.figure(figsize=(24,16))\n",
    "    (loss, acc, val_loss, val_acc) = model_history.history.values()\n",
    "    for (title, train, val, pos, loc) in [[\"Accuracy\", acc, val_acc, \"lower right\", 1], [\"Loss\", loss, val_loss, \"upper right\", 2]]:\n",
    "        plt.subplot(1, 2, loc)\n",
    "        plt.title(f\"Training vs Validation {title}\")\n",
    "        plt.plot(range(epochs), train, label=f\"Train {title}\")\n",
    "        plt.plot(range(epochs), val, label=f\"Val {title}\")\n",
    "        plt.legend(loc=pos)\n",
    "        plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb700494-ea98-47b7-96e6-f7fde435b9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_vs_val(nadam_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac45a268-d4e5-4740-bbc9-67f3cf2d9914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(model, img):\n",
    "    img_array = tf.expand_dims(tf.keras.preprocessing.image.img_to_array(img), 0)\n",
    "    preds = model.predict(img_array)[0]\n",
    "    pred_label = CLASS_NAMES[np.argmax(preds)]\n",
    "    confidence = round(100 * (np.max(preds)), 2)\n",
    "    return pred_label, confidence\n",
    "\n",
    "\n",
    "def display_single_prediction_from_batched_set(batched_data):\n",
    "    for images_batch, labels_batch in from_set.take(1):\n",
    "        index = random.randint(0, len(images_batch)-1)\n",
    "        image = images_batch[index].numpy().astype(\"uint8\")\n",
    "        actu_label = CLASS_NAMES[labels_batch[index].numpy()]\n",
    "        pred_label, conf = predict_image(CNN, image)\n",
    "        print(f\"Predicted Label: {pred_label}\")\n",
    "        print(f\"Actual Label:    {actu_label}\")    \n",
    "        print(f\"Confidence:      {conf}\") \n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(image)\n",
    "\n",
    "\n",
    "def display_multiple_predictions_from_batched_set(batched_data, num_rows, num_cols):\n",
    "    num_images = num_rows*num_cols\n",
    "    plt.figure(figsize=(16, num_images*2))\n",
    "    for images, labels in from_set.take(1):\n",
    "        for i in range(num_images):\n",
    "            pred_label, conf = predict_image(CNN, images[i].numpy())\n",
    "            actual_label = CLASS_NAMES[labels[i]]\n",
    "            plt.subplot(num_rows, num_cols, i+1)            \n",
    "            plt.title(f\"Actual: {actual_label}, \\n Predicted: {pred_label}, \\n Confidence: {conf}\")\n",
    "            plt.axis(\"off\")\n",
    "            plt.imshow(images[i].numpy().astype(\"uint8\"))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73ac464f-9428-4585-bc10-67e9fd6d1b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_h5_model(model, path=\"./h5_models/\"):\n",
    "    model_val = len(os.listdir(path))\n",
    "    model.save(f\"{path}{len(model_val) + 1}.h5\")\n",
    "    return f\"Model saved as {len(model_val)}.h5\"\n",
    "\n",
    "\n",
    "def save_default_model(model, alt_version=None, path=\"models/\"):\n",
    "    saved_models = [float(x.split('-')[1]) for x in os.listdir(path)]\n",
    "    if len(saved_models) == 0:\n",
    "        model.save(f\"{path}{model.name}-1.0\")\n",
    "    elif alt_version is not None:\n",
    "        alt_version = float(math.floor(alt_version))\n",
    "        if saved_models.count(alt_version) != 0:\n",
    "            prevs_index = (len([x for x in saved_models if int(x) <= int(alt_version)])-1)\n",
    "            prev_version = saved_models[prevs_index]\n",
    "            if round(prev_version - 0.9, 1) == alt_version:\n",
    "                print(\"Max alternate models reached, create another base version.\")\n",
    "            else:\n",
    "                model.save(f\"{path}{model.name}-{round(prev_version + .1, 1)}\")\n",
    "        else:\n",
    "            print(\"New version created\")\n",
    "            model.save(f\"{path}{model.name}-{alt_version}\")\n",
    "    else:\n",
    "        model_version = saved_models[-1]\n",
    "        model.save(f\"{path}{model.name}-{float(int(model_version + 1))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc6adb6-fbcd-4045-8c3d-6ca71f90553f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f5aff8-9c44-4985-b7b6-5dd2ad349c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using ImageDataGenerator & spilt datasets\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Using split_folders python package to easily split the data\n",
    "# Run the following in terminal: \n",
    "# split_folders --output split_dataset --ratio .7 .1 .2 -- data/\n",
    "# After this our data is setup for the following block\n",
    "split_dataset = \"split_dataset\"\n",
    "\n",
    "datagen_params = dict(rescale=1./255, horizontal_flip=True, rotation_range=10)\n",
    "generator_params = dict(target_size=IMAGE_SIZE, batch_size=BATCH_SIZE, class_mode=\"sparse\")\n",
    "\n",
    "train_datagen = ImageDataGenerator(**datagen_params)\n",
    "val_datagen = ImageDataGenerator(**datagen_params)\n",
    "test_datagen = ImageDataGenerator(**datagen_params)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(split_dataset+\"/train\", **generator_params)\n",
    "val_generator = val_datagen.flow_from_directory(split_dataset+\"/val\", **generator_params)\n",
    "test_generator = test_datagen.flow_from_directory(split_dataset+\"/test\", **generator_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702f23bb-1b81-40f8-9238-17ec3120f84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_test_generator(model, train_gen, val_gen, test_gen, batch_size, epochs):\n",
    "    history = model.fit(train_generator, steps_per_epoch=len(train_gen), \n",
    "                        validation_data=val_generator, validation_steps=len(val_gen), \n",
    "                        batch_size=batch_size, epochs=epochs, \n",
    "                        verbose=1,\n",
    "                        workers=1, use_multiprocessing=False, \n",
    "                        class_weight=None\n",
    "                    )\n",
    "    test_score = model.evaluate(test_gen)\n",
    "    return history, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa56d950-2909-4d45-9846-4c685ee2c58f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74724382-4cf6-428b-b163-081b6689a174",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "    tf.keras.metrics.CategoricalCrossentropy(name=\"CategoricalCrossentropy\"),\n",
    "    tf.keras.metrics.CategoricalAccuracy(name=\"CategoricalAccuracy\"),\n",
    "    \n",
    "    tf.keras.metrics.TruePositives(name=\"TruePositives\"),\n",
    "    tf.keras.metrics.FalsePositives(name=\"FalsePositives\"),\n",
    "    tf.keras.metrics.TrueNegatives(name=\"TrueNegatives\"),\n",
    "    tf.keras.metrics.FalseNegatives(name=\"FalseNegatives\"),\n",
    "    \n",
    "    tf.keras.metrics.Precision(name=\"Precision\"),\n",
    "    tf.keras.metrics.Recall(name=\"Recall\"),\n",
    "    tf.keras.metrics.PrecisionAtRecall(0.5, name=\"PrecisionAtRecall\"),\n",
    "    tf.keras.metrics.RecallAtPrecision(0.5, name=\"RecallAtPrecision\"),\n",
    "    tf.keras.metrics.SensitivityAtSpecificity(0.5, name=\"SensitivityAtSpecificity\"),\n",
    "    tf.keras.metrics.SpecificityAtSensitivity(0.5, name=\"SpecificityAtSensitivity\"), \n",
    "    \n",
    "    tfa.metrics.F1Score(num_classes=NUM_CLASSES, threshold=0.5, name=\"F1Score\"),\n",
    "    tfa.metrics.FBetaScore(num_classes=NUM_CLASSES, threshold=0.5, name=\"FBetaScore\"),\n",
    "    tfa.metrics.MultiLabelConfusionMatrix(num_classes=NUM_CLASSES),\n",
    "\n",
    "    tf.keras.metrics.AUC(name='AUC', from_logits=False),\n",
    "    tf.keras.metrics.AUC(name='ROC', curve='ROC', from_logits=False),\n",
    "    tf.keras.metrics.AUC(name='PRC', curve='PR', from_logits=False),\n",
    "]\n",
    "\n",
    "metric_names = [i.name for i in METRICS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3dce4d-e069-4a82-9ee6-9dabb41059e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with metrics outside of accuracy because of class imbalance\n",
    "BATCHED_DATASET_2 = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=DATA_DIR, label_mode='categorical', shuffle=True, image_size=IMAGE_SHAPE, batch_size=BATCH_SIZE\n",
    ")\n",
    "train_set, val_set, test_set = split_tf_dataset_train_val_test(BATCHED_DATASET_2, shuffle=True)\n",
    "train_set = train_set.cache().shuffle(10000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_set = val_set.cache().shuffle(10000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_set = test_set.cache().shuffle(10000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "CNN = build_cnn()\n",
    "nadam = CNN.compile(\n",
    "    optimizer=\"Nadam\",\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "    metrics=METRICS\n",
    ")\n",
    "nadam_history_2, nadam_test_score_2 = fit_and_test(CNN, train_set, val_set, test_set)\n",
    "metric_results_2 = dict(zip(metric_names, nadam_test_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
